{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#recent-posts","title":"Recent Posts","text":"<p>{{ blog_content }}</p> <p>Have an average day :| </p>"},{"location":"tags/","title":"Tags","text":"<p>Following is a list of relevant tags:</p>"},{"location":"tags/#ansible","title":"ansible","text":"<ul> <li>Ansible - How to write a playbook</li> <li>Ansible - Getting Started</li> </ul>"},{"location":"tags/#arch","title":"arch","text":"<ul> <li>Linux</li> </ul>"},{"location":"tags/#audio","title":"audio","text":"<ul> <li>FFMPEG and YOU!</li> </ul>"},{"location":"tags/#chicken","title":"chicken","text":"<ul> <li>Marry Me Chicken</li> </ul>"},{"location":"tags/#chicken-recipes","title":"chicken recipes","text":"<ul> <li>Marry Me Chicken</li> </ul>"},{"location":"tags/#chocolatey","title":"chocolatey","text":"<ul> <li>Windows</li> </ul>"},{"location":"tags/#debian","title":"debian","text":"<ul> <li>Linux</li> </ul>"},{"location":"tags/#docker","title":"docker","text":"<ul> <li>Docker</li> </ul>"},{"location":"tags/#ffmpeg","title":"ffmpeg","text":"<ul> <li>FFMPEG and YOU!</li> </ul>"},{"location":"tags/#frontmatter","title":"frontmatter","text":"<ul> <li>Markdown Metadata, its meta-tastic!</li> </ul>"},{"location":"tags/#git","title":"git","text":"<ul> <li>GIT</li> <li>SSH</li> </ul>"},{"location":"tags/#ipfs","title":"ipfs","text":"<ul> <li>This is My Second IPFS Post</li> <li>This is My First IPFS Post</li> </ul>"},{"location":"tags/#json","title":"json","text":"<ul> <li>JSON</li> </ul>"},{"location":"tags/#linux","title":"linux","text":"<ul> <li>MDRAID</li> </ul>"},{"location":"tags/#macos","title":"macos","text":"<ul> <li>Docker</li> </ul>"},{"location":"tags/#makemkv","title":"makemkv","text":"<ul> <li>FFMPEG and YOU!</li> </ul>"},{"location":"tags/#mariadb","title":"mariadb","text":"<ul> <li>MYSQL</li> </ul>"},{"location":"tags/#markdown","title":"markdown","text":"<ul> <li>Markdown Metadata, its meta-tastic!</li> </ul>"},{"location":"tags/#mdraid","title":"mdraid","text":"<ul> <li>MDRAID</li> </ul>"},{"location":"tags/#metadata","title":"metadata","text":"<ul> <li>Markdown Metadata, its meta-tastic!</li> </ul>"},{"location":"tags/#mysql","title":"mysql","text":"<ul> <li>MYSQL</li> </ul>"},{"location":"tags/#podman","title":"podman","text":"<ul> <li>Docker</li> </ul>"},{"location":"tags/#powershell","title":"powershell","text":"<ul> <li>Windows</li> </ul>"},{"location":"tags/#putty","title":"putty","text":"<ul> <li>SSH</li> </ul>"},{"location":"tags/#python","title":"python","text":"<ul> <li>Python</li> </ul>"},{"location":"tags/#raid","title":"raid","text":"<ul> <li>MDRAID</li> </ul>"},{"location":"tags/#rhel","title":"rhel","text":"<ul> <li>Linux</li> </ul>"},{"location":"tags/#rocky","title":"rocky","text":"<ul> <li>Linux</li> </ul>"},{"location":"tags/#ssh","title":"ssh","text":"<ul> <li>Ansible - Getting Started</li> <li>SSH</li> </ul>"},{"location":"tags/#storage","title":"storage","text":"<ul> <li>MDRAID</li> </ul>"},{"location":"tags/#svn","title":"svn","text":"<ul> <li>SVN</li> </ul>"},{"location":"tags/#tar","title":"tar","text":"<ul> <li>TAR</li> </ul>"},{"location":"tags/#ubuntu","title":"ubuntu","text":"<ul> <li>Linux</li> </ul>"},{"location":"tags/#vi","title":"vi","text":"<ul> <li>VIM</li> </ul>"},{"location":"tags/#video","title":"video","text":"<ul> <li>FFMPEG and YOU!</li> </ul>"},{"location":"tags/#vim","title":"vim","text":"<ul> <li>VIM</li> </ul>"},{"location":"tags/#windows","title":"windows","text":"<ul> <li>Windows</li> </ul>"},{"location":"tags/#winget","title":"winget","text":"<ul> <li>SSH</li> <li>Windows</li> </ul>"},{"location":"blog/","title":"\ud83c\udf1f Hello there \ud83d\udc4b","text":"<ul> <li>\ud83d\udd2d I\u2019m currently working on HPC &amp; Cloud</li> <li>\ud83c\udf31 I\u2019m currently learning Rust &amp; Warewulf</li> <li>\ud83d\udc6f I\u2019m looking to collaborate on HPC, Ansible, Scripting &amp; Automation, Rocky Linux (Or any EL Linux)</li> <li>\ud83e\udd14 I\u2019m looking for help with Warewulf, Rocky Linux</li> <li>\ud83d\udcac Ask me about HPC, OS Deployments, and Systems Automation! THAT'S MY JAM!</li> <li>\ud83d\udceb How to reach me: Submit an Issue, Email me, or 146.52 MHZ</li> <li>\ud83d\ude04 Pronouns: He/Him</li> <li>\u26a1 Fun fact: I solved a rubik's cube\u2026 by accident\u2026 once</li> </ul> <p>Here's a few popular things I know about:</p> <p>[</p>"},{"location":"blog/IPFS%20Second%20Post/","title":"This is My Second IPFS Post","text":"<p>Dumped everything and started over with mkdocs + mkdocs-material.</p> <p>You can reach this site a few different ways via ipfs</p> <ul> <li>w4ugh.radio</li> <li>blog.techcabbage.xyz</li> <li>IPNS via dweb.link</li> </ul> <p>All three use ipns and the first two use it via cloudflare. The last one via ipfs.io / dweb.link.</p> <p>No pinning services are paid for so you get what you get. :|</p>","tags":["ipfs"]},{"location":"blog/Markdown%20Metadata/","title":"Markdown Metadata, It's META-TASTIC","text":"<p>If you ever have needed to include meta with your markdown, take a look at the yaml metadata you can add to markdown. The only one that I've found that isn't supported by everything is tags. Otherwise everything just seems to work great</p> <pre><code>---\ntitle: Markdown Metadata, its meta-tastic!\nauthor: Hugh Smalley\naffiliation: https://hsmalley.github.io\ndate: 2023-03-20\ncopyright: CC-BY-SA\ncomment:\ntags: [tag, tag2]\n---\n</code></pre> <p>You can also do tags like this</p> <pre><code>tags:\n- tag 1\n- tag 2\n</code></pre> <p>Using metadata will let you organize and do things that you didn't think were possible with markdown. If you use something like Obsidian then you can pair it with dataview and fly away on some a magic markdown carpet!</p>","tags":["markdown","metadata","frontmatter"]},{"location":"blog/ipfs-first-post/","title":"This is My IPFS First Post","text":"<p>Well first post to this block. I retired my old blog after letting it limp along for years. I'm ready for a new fresh start. So I figured why not use IPFS and Hugo? I'm pretty sure it should be easy to do. Though I'm seeing that Jekyll might be better. I'm not well versed in Ruby so I'm trying to avoid it.</p> <p>So what is this space going being used for? Mostly just geeky after action reports I suppose. My hobbies have expanded and changed a lot over years. So I'm guessing this will have things related to microcontrollers, general sysadmin stuff, python, ham radio, and cooking.</p> <p>Right now I'm curious how much of my old blog I can bring over that is still relevant, how well IPFS handles things, and if I can somehow tie all of this into packet radio!</p>","tags":["ipfs"]},{"location":"blog/ipfs-first-post/#what-is-ipfs","title":"What is IPFS?","text":"<p>So for those of you wondering WHAT IS IPFS? I'll explain it in a way that you might understand using some words you might already know. It's a peer to peer system that instead of addressing content where it's located eg youtube.com it's addressing content by it's ID. Meaning that a video on youtube might be something like https://youtu.be/dQw4w9WgXcQ would be QmdNBsDWQ1JKrt6ynYuQQpL2NzUVJ5eTLW6bz129S1bLsV on the IPFS network. The advantage to this is that even if youtube were to vanish one day. As long as even ONE peer on the IPFS network has that content then you can get to it. Since throwing around hashes aren't really useful for everyday use that's were IPNS and IPFS gateway's really come in handy. We can set it so that it uses DNS. Kind of like how instead of going to some IP Address like 1.1.1.1 you go to a website eg youtube.com. This is the same kinda thing here, it even allows people who do not have an IPFS client built into their browser eg Opera, Brave, etc. to view the content. On a side note if you want to add IPFS to your browser there's extensions and a desktop client.</p>","tags":["ipfs"]},{"location":"how-to/Ansible%20-%20Playbooks/","title":"Ansible - How to write a playbook","text":"<p>How-to: Write an Ansible Playbook</p> <p>The general layout of the a playbook:</p> <pre><code>---\n# How to use:\n# ansible-playbook -i inventory/inventory.file.here playbooks/template.yml\n- name: Playbook name\nhosts: all\nbecome: false # Change to true for sudo powers\nvars: # Any vars needed for this playbook\nhandlers: # Any handlers needed for this playbook\npre_tasks: # Any pre-tasks needed for this playbook\npost_tasks: # Any post-tasks needed for this playbook\ntasks: # The main body of the playbook\n</code></pre> <p>Playbooks should follow this layout where possible. You may have some things that require more or less.</p>","tags":["ansible"]},{"location":"how-to/Ansible%20-%20Playbooks/#formatting-and-general-rules","title":"Formatting and General Rules","text":"","tags":["ansible"]},{"location":"how-to/Ansible%20-%20Playbooks/#general-rules","title":"General Rules","text":"<ul> <li>Every play should be named started with a capital letter</li> <li>Try to to keep lines under 80 col in length</li> <li>Use true or false to maintain truthy (yaml spec)</li> <li>Place tags where it makes sense</li> <li>Place options at the top of a block when possible; this helps with readability</li> <li>Place optionals above the module where possible; this helps with readability</li> <li>Comments should have two spaces # a single space, then the text (yaml &amp; markdown spec)</li> <li>Names should end with a letter where possible</li> <li>Registers &amp; variable names should not contain non alpha characters when possible.</li> <li>Anything that makes changes to the system when run should be handler when at all possible</li> <li>If you have to do ignore errors on something you either have a very niche edge case or it's lazy code. Anything that ignores errors should be a handler too.</li> </ul> <p>Bad Formatting</p> <pre><code>ansible.posix.authorized_key: #Adding OPS Keys to the root for some silly reasons\nuser: root\nstate: present\nkey: \"{{ item }}\"\nloop: \"{{ keys }}\"\nnotify: YouHaveBeenWarned\nignore_errors: yes\n</code></pre> <p>What's wrong with this?</p> <ul> <li>There is no name that starts with a capital letter</li> <li>There is a comment that isn't spaced out correctly and goes way past 80 col.</li> <li>Options are at the bottom rather than the top.</li> <li>Contains ignore_errors and yes</li> <li>No tags</li> </ul> <p>Good Formatting</p> <pre><code>- name: Add OPS Authorized Keys\nnotify: YouHaveBeenWarned\ntags: [keys, ssh]\nansible.posix.authorized_key:\nuser: root\nstate: present\nkey: \"{{ item }}\"\nloop: \"{{ keys }}\"\n</code></pre> <p>Why is this better?</p> <ul> <li>The task is named clearly and correctly</li> <li>You know right away that it is tagged and will trigger a handler</li> <li>Does not break truthy or ignore errors</li> <li>Does not have an unnecessary or overly long comment</li> </ul>","tags":["ansible"]},{"location":"how-to/Ansible%20-%20Playbooks/#formatting-linting","title":"Formatting &amp; Linting","text":"<p>If you follow the general rules then you should be able to format your playbooks with something like <code>prettier</code> and run <code>ansible-lint</code> on them. This will let you know if you have any errors that require fixing. You goal is to need none or as few ignores in your <code>.ansible-lint-ignore</code> file and be as close to the production ready profile as possible.</p> <p> </p> <p>If you encounter problems with your playbook that are formatting related running <code>yamlfix</code> then <code>prettier</code> on them will normally fix them for you.</p> <p>Once your playbook has been formatted and linted you can try it out. The first step</p> <p>[[Technical Notes]]</p>","tags":["ansible"]},{"location":"how-to/Ansible/","title":"Ansible or How to Mess up AT SCALE!","text":"","tags":["ansible","ssh"]},{"location":"how-to/Ansible/#getting-started","title":"Getting Started","text":"<p>To get started you will need two things: Text Editor, Python 3. You can use whatever text editor you want to use, Visual Studio Code is a popular one that runs almost anywhere. As long as you're comfortable with it, use it. If you can run python and ssh you have everything else you need.</p> <p>Note</p> <ul> <li> <p>It is possible to run this on Windows itself, I do not use Windows so I can not help too much. If you have WSL working then you should be able to everything. If you're having problems we do have other systems that can be used</p> </li> </ul> <p> </p> <p>Ansible is in most package repos, for this we're using ansible-core. I recommend you install it via pip to you can ensure you have the same thing as we use in prod</p> <p>Installing ansible is pretty easy, either use your package manager or pip</p> <pre><code># pip\npip install --user ansible-core\n# Redhat Systems\ndnf install ansible\n# Debian Systems\napt install ansible\n</code></pre> <p>Once you have ansible installed let's run our first command to make sure everything is in good working order <code>ansible -i localhost localhost -m ping</code></p> <p>Success</p> <pre><code>\u276f ansible localhost -m ping\nlocalhost | SUCCESS =&gt; {\n\"changed\": false,\n    \"ping\": \"pong\"\n}\n</code></pre> <p>See that was pretty easy!</p>","tags":["ansible","ssh"]},{"location":"how-to/Ansible/#my-first-inventory-file","title":"My First Inventory File","text":"<p>The next thing we're going to do is create a very simple inventory.ini file.</p> <p>Example</p> <pre><code>[mygroup_name]\nlocalhost\n</code></pre> <p>This file does one thing, tells ansible that <code>localhost</code> is in <code>my_group</code></p> <p>That's all it does! Let's run our command again, this time using the inventory file.</p> <p>Success</p> <pre><code>\u276f ansible -i inventory.ini my_group -m ping\nlocalhost | SUCCESS =&gt; {\n\"changed\": false,\n    \"ping\": \"pong\"\n</code></pre> <p>So we told ansible to use our inventory file <code>-i inventory.ini</code> and that we want to connect to <code>my_group</code> and run the ping module.</p> <p> </p> <p>What if we wanted to run against all the hosts in our inventory file? We would use the special group named <code>all</code></p> <p>[!success]</p> <p><pre><code>\u276f ansible -i inventory.ini all -m ping\nlocalhost | SUCCESS =&gt; {\n\"ansible_facts\": {\n\"discovered_interpreter_python\": \"/usr/bin/python3\"\n},\n   \"changed\": false,\n   \"ping\": \"pong\"\n}\n</code></pre> </p> <p>We can run commands too!</p> <p>Success</p> <pre><code>\u276f ansible localhost -m ansible.builtin.command -a \"ls\"\nlocalhost | CHANGED | rc=0 &gt;&gt;\nApplications\nDesktop\nDocuments\nDownloads\nLibrary\nOld Laptop\nOneDrive - Reed Elsevier Group ICO Reed Elsevier Inc\nPictures\nPublic\ngit\ninventory.ini\nsvn\n</code></pre> <p>This told ansible that I want to run <code>ls</code> on <code>localhost</code> Let's try something a little more fun!</p> <p>Success</p> <pre><code>\u276f ansible -i inventory.ini all -m ansible.builtin.command -a \"echo (\u256f\u00b0\u25a1\u00b0)\u256f\ufe35 \u253b\u2501\u253b D O N T P A N I C\"\nlocalhost | CHANGED | rc=0 &gt;&gt;\n(\u256f\u00b0\u25a1\u00b0)\u256f\ufe35 \u253b\u2501\u253b D O N T P A N I C\n</code></pre> <p>What changed there? We told ansible that we want to use the <code>ansible.builtin.command</code> module. Ansible assumes that if you do not specify a module name that you just want to run an adhoc command. So what's a module? Simply put module is a connection of stuff that tells ansible how to do do stuff.</p> <p>Let's take this another step farther, how about we use ansible to make sure my mac does not have the dreaded <code>sl</code> command!</p> <p>Example</p> <pre><code>\u276f ansible -i inventory.ini my_group -m community.general.homebrew -a \"name=sl state=absent\" localhost | SUCCESS =&gt; {\n\"changed\": false,\n   \"changed_pkgs\": [],\n   \"msg\": \"Package already uninstalled: sl\",\n   \"unchanged_pkgs\": [\n\"sl\"\n]\n}\n</code></pre> <p>We can see that it says <code>\"changed:\" false</code> that means that it was not there. So no worries about being punished for messing up up a <code>ls</code></p> <p>And now let's make sure I have the wonderful <code>toilet</code> command!</p> <p>Example</p> <pre><code>\u276f ansible localhost -m community.general.homebrew -a \"name=toilet state=present\"\nlocalhost | CHANGED =&gt; {\n\"changed\": true,\n   \"changed_pkgs\": [\n\"toilet\"\n],\n   \"msg\": \"Package installed: toilet\",\n   \"unchanged_pkgs\": []\n}\n</code></pre> <p>So now we know how to use ad hoc commands. We can run them on all the hosts in our inventory file or just a group. What if we want to do more?</p> <p> </p> <p>Using the flag <code>--limit</code> we can limit ansible to one host or just a group of hosts e.g. <code>-- limit hostname.here.local</code></p>","tags":["ansible","ssh"]},{"location":"how-to/Ansible/#yaml-what-the-hell-is-a-yaml","title":"Yaml? What the Hell is a Yaml?","text":"<p>YAML stands for YAML Ain\u2019t Markup Language. It's what most things use to store key value pairs in a way that humans can manage and understand without too much help. Pretty much everything with Ansible, (and most cloud stuff), uses yaml. When it comes to ansible it only cares about the content of the file and not the name, so you can use <code>.yml</code> or<code>.yaml</code>it only really matters to the humans (and sometimes Windows)</p> <p> </p> <p>Yaml can be a real pain so do yourself a favor, use a linter <code>pip install --user yamllint yamlfix prettier</code></p> <p>What the hell is a linter?  </p> <p>A linter is something that makes sure you code is functional. It will let you know where things are broken and maybe give you a hint on how to fix it. A formatter can help with that, while It doesn't check if it is actually good or functional it tries to make it readable. So you should be using <code>yamllint</code> to check your files for problems and <code>yamlfix</code> to help fix them automatically. Once your good you can use <code>prettier -w</code> to make it pretty. Don't worry, there's ways of automating this</p> <p>Let's just jump right into the deep end and make an inventory file using yaml. Ideally any inventory file you will be using will be some kind of yaml. It doesn't matter if it's for ansible or kubernetes for example. Let's take a look at a simple inventory.yaml file</p> <p>Example</p> <pre><code>---\nall:\nhosts:\nalice:\nbob:\n</code></pre> <p>Here way have two hosts: alice &amp; bob. If this was in ini it would look like</p> <pre><code>[hosts]\nalice\nbob\n</code></pre> <p>So not much of a different from our first inventory.ini We can check this file with the <code>ansible-inventory</code> command</p> <pre><code>\u276f ansible-inventory -i simple.yml --graph\n@all:\n  |--@ungrouped:\n  |  |--alice\n  |  |--bob\n</code></pre> <p>Nothing really complex so far, let's add some more hosts and groups into our inventory.yml</p> <p>Example</p> <pre><code>--all:\nhosts:\nalice:\nbob:\nchildren:\ngroup_1:\nhosts:\nstrangechicken:\ntumescentcloaca:\ngroup_2:\nhosts:\nwowzer:\nimaproblem:\ngroup_3:\nhosts:\ngroup_1:\nalice:\ngroup_4:\nhosts:\ngroup_2:\nbob:\ngroup_5:\nhosts:\ngroup_3:\ngroup_4:\n</code></pre> <p>As you can see we can have many groups even groups that have other groups inside them. We can keep nesting groups as long as we follow the hosts, children, hosts naming. We can make sure this is a valid inventory by looking at with <code>ansible-inventory</code></p> <pre><code>\u276f ansible-inventory -i inventory.yml --graph\n@all:\n  |--@ungrouped:\n  |--@group_1:\n  |  |--strangechicken\n  |  |--tumescentcloaca\n  |--@group_2:\n  |  |--wowzer\n  |  |--imaproblem\n  |--@group_3:\n  |  |--group_1\n  |  |--alice\n  |--@group_4:\n  |  |--group_2\n  |  |--bob\n  |--@group_5:\n  |  |--group_3\n  |  |--group_4\n</code></pre>","tags":["ansible","ssh"]},{"location":"how-to/Ansible/#my-first-playbook","title":"My First Playbook","text":"<p>Now running commands one at a time is fine but it's a lot more fun to have something that does a lot of things on a lot of things. This is where Ansible shines!</p> <p>This is also where things start to get more information dense. So buckle up!</p> <p>Ansible will not change anything that doesn't need to be changed, this is important for ensuring something called idempotency. That means that no matter how many times we run the same thing, we're going to get the same results.</p> <p>Let's take a look at a simple but real playbook: <code>change_genesis.yml</code></p> <p>Example</p> <pre><code>---\n- name: Change Genesis Server\nhosts: all\nbecome: true\nvars:\ngenesis_ip: 10.194.118.129\nfiles_to_change:\n- /etc/profile.d/genesis.sh\n- /etc/resolv.conf\n- /etc/profile.d/yum.sh\ntasks:\n- name: Replace Bad Genesis\nansible.builtin.replace:\ndest: \"{{ item }}\"\nregexp: 10\\.173\\.0\\.129\nreplace: \"{{ genesis_ip }}\"\nloop: \"{{ files_to_change }}\"\n</code></pre> <p>So what does this do? It may look complicated but it's fairly simple. This says look at these files for this string and replace it with that string.</p> <p>Starting from the top we have <code>name:</code> this is the name of the play. The play is what ansible calls it's group of actions or a single action. All plays should be named starting with a capital letter and end with a letter. It will still work if you do not do this, but it will complain the entire time. Kinda like when you don't put on your seat belt\u2026</p> <p>Next <code>hosts:</code> and <code>become:</code> this is the host, hosts, and or group name to run this on. Most of the time this is going to set to <code>all</code>. <code>become:</code> tells ansible that it needs to use sudo aka root powers to do these tasks. The higher up in the play the more things will use sudo powers.</p> <p>Now <code>vars:</code> is a special:</p> <p>Like <code>become:</code> it can be used most anywhere in a play, or it can reference other yaml files. So if we were to put vars in something like our inventory file it would apply per host, per group, or even for everything! In this case we're only saying that the plays before need these variables. Variables can also be anything we want. If I want foo to have the value of bar then I put <code>foo: bar</code>.</p> <p><code>genesis_ip:</code> is the ip to the genesis server in this case we're using<code>10.194.118.129</code> <code>files_to_change:</code> lists the files that we need to check.</p> <p>Further down we get to <code>tasks:</code> tasks are the plays that that playbook is running. In this case we have single play named <code>Replace Bad Genesis</code>. The module name is <code>ansible.builtin.replace</code> that makes it function like <code>sed</code>. The next lines are telling it where and what. <code>dest:</code> is the destination file, <code>regexp:</code> is a regular expression, and <code>replace:</code> is what is going to replace the matched expression.</p> <p>This play has something special attached to it called a <code>loop:</code> this tells the play that there's going to be more things to do so it will function in a loop, kind of like <code>for x in</code> a bash loop.</p> <p>When you call a variable in you have to use another kind of language aside from yaml. It's a templating language/engine called Jinja2. Templating languages (engines) have been around for long time. They allow us to define how things should look while still allowing us to program-maticly change things. DO NOT WORRY, much like regex, you will not need to know it like you will need to understand yaml.</p> <p>To call variables we're using jinja values. So in this case the files are represented by <code>\"{{ item }}\"</code> and the list of files is represented by <code>\" {{ files_to_change }}\"</code> this is more than likely the most complex jinja you will have to remember. The various linter's will handle the rest if you mess it up. So do not worry to much!</p> <p>Let's look at the same thing done in bash</p> <p>Example</p> <pre><code>sed -i 's/10.173.0129/10.194.118.129/g' /etc/profile.d/genesis.sh\nsed -i 's/10.173.0129/10.194.118.129/g' /etc/resolv.conf\nsed -i 's/10.173.0129/10.194.118.129/g' /etc/profile.d/yum.sh\n</code></pre> <p>Now lets look at a script to do the same thing</p> <p>Example</p> <pre><code>#!/bin/bash\ngenesis_ip=10.194.119.129\nbad_genesis=10.173.0.129\nfiles=(/etc/profile.d/yum.sh, /etc/resolv.conf, /etc/profile.d/yum.sh)\nfor file in ${files[@]}; do\nsed -i \"s/${bad_genesis}/${genesis_ip}/g\" \"${file}\"\ndone\n</code></pre> <p>You could also use the get a bigger hammer approach too <code>grep -rl \"10.173.0.129\" | xargs sed 's/10.173.0.129/10.194.118.129/g'</code> there's a lot of ways to do the same thing. So why do it with Ansible? Well idempotency aside we do not have to worry about what system is on the other end. That same module will work the same on Linux, Mac, Windows, BSD, etc. We can also chain multiple playbooks together in ways that trying to string together multiple shell scripts start to fail at. Radssh is an incredible tool but it will only get you so far. Ansible provides a way to validate your configurations and document them in ways that other methods just simply can not do.</p>","tags":["ansible","ssh"]},{"location":"how-to/Ansible/#digressions-aside-how-do-you-actually-run-the-damn-thing","title":"Digressions Aside; how Do You Actually Run the Damn Thing!?","text":"<p>&gt; <code>ansible-playbook -i inventory.yml all -u USERNAME -k change_genesis.yml</code></p> <p>Let's break this down. <code>ansible-playbook</code> is the command that handles playbooks, kind of like we used <code>ansible-inventory</code> to look at out inventory file. <code>-i inventory.yml all</code> says use all the hosts in the inventory file. <code>-u USERNAME -k</code> says use this username and prompt for a sudo password so it can be used when needed. Some depending on how sudoers is configured you can leave this out. For most admin/op account <code>-k</code> isn't needed. Lastly the name of the playbook <code>change_genesis.yml</code></p>","tags":["ansible","ssh"]},{"location":"how-to/Ansible/#the-end-ish","title":"The End-ish","text":"<p>This is has been an overview on Ansible. It is by no means a complete or even good overview. It's purely from my memory and there are bounds to be gaps or things I'm making assumptions about. I will be adding this document to github in the future once I am mostly satisfied with it's content.</p> <p>As with everything in life; YMMV, caveat emptor, pass performance doesn't equal future success, and\u2026</p> <p>Have an Average Day :|</p> <p>metadata [[Technical Notes]]</p>","tags":["ansible","ssh"]},{"location":"how-to/Docker/","title":"Docker","text":"<p>Docker with MiniKube &amp; Podman</p> <p>https://dhwaneetbhatt.com/blog/run-docker-without-docker-desktop-on-macos</p> <p>[[Run Docker without Docker Desktop on macOS Dhwaneet Bhatt.pdf]]</p> <p>[[Technical Notes]]</p>","tags":["macos","docker","podman"]},{"location":"how-to/FFMPEG/","title":"Using <code>ffmpeg</code>","text":"","tags":["ffmpeg","makemkv","video","audio"]},{"location":"how-to/FFMPEG/#combine-video-files","title":"Combine Video Files","text":"<p>First make a video stream file. All this is a text file with the file names in listed by <code>file 'filename.mkv'</code> for each file. Here is a quick and easy way to generate that file:</p> <p>Example</p> <pre><code>printf \"file '%s'\\n\" *.mkv &gt; mylist.txt\n</code></pre> <p>Next you need to tell <code>ffmpeg</code> that you're going to combine the file with the <code>concat</code> format. In this example I was converting a DVD I dumped with <code>makemkv</code>. Since they're all using the same formats and resolutions I didn't have to worry about adding a bunch of stuff. I also had it write it to <code>mp4</code> and made me easier for Plex to stream it with the <code>movflags</code>.</p> <p>Example</p> <pre><code>ffmpeg -fflags +genpts -f concat -safe 0 -i mylist.txt -c copy -movflags +faststart -movflags use_metadata_tags Your.File.Name.mp4\n</code></pre>","tags":["ffmpeg","makemkv","video","audio"]},{"location":"how-to/FFMPEG/#removing-tracks-from-a-file","title":"Removing Tracks from a File","text":"<p>First find all the mappings in the file by doing <code>ffmpeg -i video.file.here.mp4</code></p> <p>You should see a few things that start with <code>Stream #0:0</code> or <code>Stream #0:1</code> and so on. Those are the various audio and video streams, yes things like mkv can have many different streams, codecs, etc. mp4, m4v, webm, etc are limited though. So lets' say I have a file that has both English and Spanish audio and I only want to keep the 2nd audio stream and drop the first. Looking at the mappings I can see that <code>0:0</code> is the video stream, so I want to keep that. I also see that I want to keep <code>0:2</code> and drop <code>0:1</code> so I will tell <code>ffmpeg</code> that I want to copy everything in the file, but I want to drop the <code>0:1</code> stream. In this example you can see that I also included flag to make it load faster and use metadata too.</p> <p>Example</p> <pre><code>ffmpeg -i video.file.here.m4v -map 0:0 -map 0:2 -c copy -movflags faststart -movflags use_metadata_tags video.output.here.mp4\n</code></pre>","tags":["ffmpeg","makemkv","video","audio"]},{"location":"how-to/FFMPEG/#setting-new-default-audio-track","title":"Setting New Default Audio Track","text":"<p>Let's remap some audio streams and set the 0:2 to the default</p> <p>Example</p> <pre><code>ffmpeg -c copy -map 0:0 -map 0:2 -map 0:1 -map 0:7 -disposition:a:0 default -disposition:a:1 none\n</code></pre> <p>Looking at the command above we're saying that in the output file audio a:0 will be the default and a:1 will not be anything. This sets whatever was the default to none and promotes the stream we want as the default. You'll see that we're also moving stream 0:2 head of stream 0:1. So in the output file stream 0:2 will in the a:0 place.</p>","tags":["ffmpeg","makemkv","video","audio"]},{"location":"how-to/FFMPEG/#change-the-language-tag-of-a-stream","title":"Change the Language Tag of a Stream","text":"<p>Lets say we have some tracks that are not tagged as the language we want. We'll add the metadata tags BEFORE the mapping. The metadata tags are going to corrospond to the output streams in their order, so taking the command above we would do</p> <p>Example</p> <pre><code>ffmpeg -i video.mp4 -c copy -metadata:s:0 language=eng -metadata:s:1 language=eng -metadata:s:2 language=eng -metadata:s:3 language=eng -map 0:0 -map 0:2 -map 0:1 -map 0:7 -disposition:a:0 default -disposition:a:1 none remapped_video.mp4\n</code></pre> <p>This command says that stream 0,1,2,3 are going to have the tag eng and we're mapping streams 0,2,1,7 from the input to and they will become streams 0,1,2,3 on the output with the default audio stream being the 0:2 on the input or 0:1 on the output.</p> <p>Let's say we want to add other information such as title information, we would add another <code>-metadata:s:0 title=\"TITLE HERE\"</code> for each stream. here's an example of remapping, dropping, and adding metadata</p> <p>Example</p> <pre><code>ffmpeg -i Highlander\\ \\(1986\\)\\ Remux-1080p\\ AV1\\ DTS-HD\\ MA\\ \\[EN+DE\\]\\ 4K4U\\ tt0091203.m4v -y -c copy -metadata:s:0 title=\"Highlander (1986) Remux-1080p x265 DTS-HD MA [E tt0091203\" -metadata:s:1 title=\"DTS-HD MA 5.1\" -metadata:s:1 language=eng -metadata:s:2 title=\"DTS-MA 2.0\" -metadata:s:2 language=eng -metadata:s:3 title=\"DTS 2.0\" -metadata:s:3 language=eng -map 0:0 -map 0:2 -map 0:1 -map 0:7 -disposition:a:0 default -disposition:a:1 none Highlander\\ \\(1986\\)\\ Remux-1080p\\ AV1\\ DTS-HD\\ MA\\ \\[EN\\]\\ tt0091203.mp4\n</code></pre> <p>Success</p> <pre><code>Output #0, mp4, to 'Highlander (1986) Remux-1080p AV1 DTS-HD MA [E tt0091203.mp4':\n\u00a0Metadata:\n\u00a0\u00a0\u00a0major_brand \u00a0\u00a0\u00a0\u00a0: mp42\n\u00a0\u00a0\u00a0minor_version \u00a0\u00a0: 512\n\u00a0\u00a0\u00a0compatible_brands: mp42av01iso2mp41\n\u00a0\u00a0\u00a0title \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0: Highlander (1986) Remux-1080p x265 DTS-HD MA [EN+D 4K4U tt0091203\n\u00a0\u00a0\u00a0encoder \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0: Lavf58.29.100\n\u00a0\u00a0\u00a0Stream #0:0(und): Video: av1 (Main) (av01 / 0x31307661), yuv420p10le(tv, bt709), 1920x1080 [SAR 1:1 DAR 16:9], q=2-31, 7534 kb/s, 24 fps, 24 tbr, 90k tbn, 90k tbc (default)\n\u00a0\u00a0\u00a0Metadata:\n\u00a0\u00a0\u00a0\u00a0\u00a0creation_time \u00a0\u00a0: 2023-02-28T21:31:32.000000Z\n\u00a0\u00a0\u00a0\u00a0\u00a0handler_name \u00a0\u00a0\u00a0: VideoHandler\n\u00a0\u00a0\u00a0\u00a0\u00a0title \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0: Highlander (1986) Remux-1080p x265 DTS-HD MA [E tt0091203\n\u00a0\u00a0\u00a0Stream #0:1(eng): Audio: dts (DTS-HD MA) (mp4a / 0x6134706D), 48000 Hz, 5.1(side), s32p (24 bit) (default)\n\u00a0\u00a0\u00a0Metadata:\n\u00a0\u00a0\u00a0\u00a0\u00a0creation_time \u00a0\u00a0: 2023-02-28T21:31:32.000000Z\n\u00a0\u00a0\u00a0\u00a0\u00a0title \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0: DTS-HD MA 5.1\n\u00a0\u00a0\u00a0\u00a0\u00a0handler_name \u00a0\u00a0\u00a0: Surround\n\u00a0\u00a0\u00a0Stream #0:2(eng): Audio: dts (DTS-HD MA) (mp4a / 0x6134706D), 48000 Hz, stereo, s16p\n\u00a0\u00a0\u00a0Metadata:\n\u00a0\u00a0\u00a0\u00a0\u00a0creation_time \u00a0\u00a0: 2023-02-28T21:31:32.000000Z\n\u00a0\u00a0\u00a0\u00a0\u00a0title \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0: DTS-MA 2.0\n\u00a0\u00a0\u00a0\u00a0\u00a0handler_name \u00a0\u00a0\u00a0: Stereo\n\u00a0\u00a0\u00a0Stream #0:3(eng): Audio: dts (DTS) (mp4a / 0x6134706D), 48000 Hz, stereo, fltp, 768 kb/s\n\u00a0\u00a0\u00a0Metadata:\n\u00a0\u00a0\u00a0\u00a0\u00a0creation_time \u00a0\u00a0: 2023-02-28T21:31:32.000000Z\n\u00a0\u00a0\u00a0\u00a0\u00a0title \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0: DTS 2.0\n\u00a0\u00a0\u00a0\u00a0\u00a0handler_name \u00a0\u00a0\u00a0: Stereo\nStream mapping:\n\u00a0Stream #0:0 -&gt; #0:0 (copy)\n\u00a0Stream #0:2 -&gt; #0:1 (copy)\n\u00a0Stream #0:1 -&gt; #0:2 (copy)\n\u00a0Stream #0:7 -&gt; #0:3 (copy)\nPress [q] to stop, [?] for help\n</code></pre>","tags":["ffmpeg","makemkv","video","audio"]},{"location":"how-to/FFMPEG/#m1-hardware-acceleration","title":"M1 Hardware Acceleration","text":"<p>Apple silicon uses <code>videotoolbox</code> for it's HW Acceleration. If you need to control the quality add <code>-q:v 50</code> to after <code>_videotoolbox</code> with the number being 0-100 where 100 is lossless.</p> <p>The M1 supports the following encode / decode codes:</p> <ul> <li><code>mpeg1_videotoolbox</code></li> <li><code>mpeg2_videotoolbox</code></li> <li><code>mpeg4_videotoolbox</code></li> <li><code>h263_videotoolbox</code></li> <li><code>h264_videotoolbox</code></li> <li><code>prores_videotoolbox</code></li> <li><code>vp9_videotoolbox</code></li> <li><code>hevc_videotoolbox</code></li> </ul> <p>Example</p> <pre><code>ffmpeg -i video_file.mp4 -c:v h264_videotoolbox -c:a copy -vf subtitles=subititles.vtt -movflags faststart -movflags use_metadata_tags video_burnin_subtitles.mp4\n</code></pre> <p>This example shows how to burn in subtitles to a video using hardware acceleration on Apple silicon, e.g. M1, while placing the ATOM upfront to easy decode / streaming.</p> <p>See Also: This Stack Exchange post Documentation on the <code>-map</code> flag</p>","tags":["ffmpeg","makemkv","video","audio"]},{"location":"how-to/GIT/","title":"GIT","text":"","tags":["git"]},{"location":"how-to/GIT/#pull-all-the-things","title":"Pull ALL THE THINGS","text":"<p>Example</p> <pre><code>git branch -r | grep -v '\\-&gt;' | sed \"s,\\x1B\\[[0-9;]*[a-zA-Z],,g\" | while read remote; do git branch --track \"${remote#origin/}\" \"$remote\"; done\ngit fetch --all\ngit pull --all\n</code></pre>","tags":["git"]},{"location":"how-to/GIT/#clone-a-bare-repo-useful-for-hosting","title":"Clone a Bare Repo, Useful for Hosting","text":"<p><code>git clone --bare --mirror --shared URI-TO-REPO</code></p> <p>If you're hosting mirrors that are done as bare repos, then you should update. This makes sure you're getting all the branches and updates. Drop this into a cron and let it run.</p> <pre><code>#!/usr/bin/env bash\ncd /srv/git || exit 1\nfor x in $(echo *.git); do\ncd \"${x}\"\necho \"Updating ${x}\"\ngit remote update\n        git --bare fetch --all\n        git --bare fetch origin *:*\n        cd ..\ndone\n</code></pre>","tags":["git"]},{"location":"how-to/GIT/#convert-a-repo-to-bare-useful-when-a-big-oopsie-happens","title":"Convert a Repo to Bare - Useful when a Big Oopsie Happens","text":"<p>Example</p> <pre><code>cd repo\nmv .git ../repo.git # renaming just for clarity\ncd ..\nrm -fr repo\ncd repo.git\ngit config --bool core.bare true\n</code></pre>","tags":["git"]},{"location":"how-to/GIT/#git-commits-failing-to-sign","title":"Git Commits failing to Sign","text":"<p>This most likely happens when pin entry is broken</p> <p>When pinentry-mac is most likely broken</p> <pre><code>brew upgrade gnupg\nbrew link --overwrite gnupg\nbrew install pinentry-mac\necho \"pinentry-program /opt/homebrew/bin/pinentry-mac\" &gt;&gt; ~/.gnupg/gpg-agent.conf\nkillall gpg-agent\n</code></pre> <p>[[Technical Notes]]</p>","tags":["git"]},{"location":"how-to/JSON/","title":"Using JSON","text":"","tags":["json"]},{"location":"how-to/JSON/#ahoy-jq","title":"Ahoy <code>jq</code>","text":"<p>Let's parse some json with <code>jq</code>. First we're going to need some json to work with. Let's use <code>ffprobe</code> to dump some from a video file</p> <p>Example</p> <pre><code>ffprobe -v quiet -print_format json -show_streams \"${video}\" &gt;\"${video}.json\"\n</code></pre> <p>Now let's take a look at the json, we can either use the file we created or pipe it directly into <code>jq</code></p> <p>Example</p> <pre><code>ffprobe -v quiet -print_format json -show_streams \"${video}\" | jq\n# OR\njq &lt; \"${video}\"\n</code></pre> <p>Let's parse the data in a few ways, ending with only selecting English subtitles. These methods can be mixed and matched as needed to get the information you require from json</p> <p>Example</p> <pre><code># Get information on the first stream in the video file\njq -r '.streams[0]' &lt;${video}\n# Get all streams\njq -r '.streams[]' &lt;${video}\n# Return only the index number of the streams\njq -r '.streams[] | .index' &lt;${video}\n# Return the index, codec name, and codec type of all video streams.\njq -r '.streams[] | {index, codec_name, codec_type' &lt;${video}\n# Return the index and codec name of only the subtitle streams\njq -r '.streams[] | select(.codec_type==\"subtitles\") | {index, codec_name}' &lt;${video}\n# Return only the subtitle streams that have a language tag\njq -r '.streams[] | select(.codec_type==\"subtitles\") | select(.tags.language)' &lt;${video}\n# Return only the subtitle streams that contain \"en\" in their language tag\njq -r '.streams[] | select(.codec_type==\"subtitles\") | select(.tags.language | contains(\"en\"))' &lt;${video}\n</code></pre> <p>[[Technical Notes]]</p>","tags":["json"]},{"location":"how-to/Linux/","title":"Linux","text":"","tags":["rocky","rhel","ubuntu","debian","arch"]},{"location":"how-to/Linux/#linux-version-checking","title":"Linux Version Checking","text":"<pre><code>lsb_release\ncat /etc/*release\n</code></pre> <p>RHEL / CENTOS</p> <pre><code>yum install redhat-lsb-core\n</code></pre>","tags":["rocky","rhel","ubuntu","debian","arch"]},{"location":"how-to/Linux/#dnf-yum-repo-mirroring-syncing-creation","title":"DNF / YUM Repo Mirroring, Syncing, Creation","text":"<p>Mirroring, Syncing, and Creating repos</p> <p>Yum: sudo yum install yum-utils createrepo</p> <p>DNF: sudo dnf install dnf-utils createrepo</p> <p>To do the initial sync</p> <pre><code>mkdir -p /mnt/your/repo/mirror/here\nreposync --repoid=REPOID --arch=x86_64 --plugins --download_path=/mnt/your/repo/mirror/here\n</code></pre> <p>This will sync whatever repoid (eg epel) you specify, only the x86_64 packages, will allow it to use the yum/dnf plugins, and sync it to your mirror dir. Omitting the repoid flag will sync ALL the repos on the system (/etc/yum.repos.d/)</p> <p>Once the mirror is created you can sync it, verify it, and delete the old packages</p> <pre><code>reposync --repoid=REPOID -arch=x86_64 --plugins --gpgcheck --delete --download_path=/mnt/your/repo/mirror/here\n</code></pre> <p>If you need to do a quick sync you can add <code>--newest-only</code> and it will just sync the newest packages. Adding the <code>--download-metadata</code> flag might be needed for some repos. For example if you want to directly use the repo without running createrepo on it.</p> <p>If you have a collection of RPMs that need to be put together in a repo, update a repo after running reposync, or fix a local mirror with bad metadata, use the <code>createrepo</code> command.</p> <pre><code>createrepo /mnt/your/repo/mirror/here\n</code></pre> <p>If you have a large repo you will want to setup a cache. This will improve your entire repo creation speed at the cost of some disk space.</p> <pre><code>mkdir -p /mnt/your/repo/mirror/here/.repocache\ncreaterepo --update --deltas --cachedir /mnt/your/repo/mirror/here/.repocache /mnt/your/repo/mirror/here\n</code></pre> <p>If you're having problems you can use the <code>--workers</code> flag to set the number workers. By default it will use as many workers as you have threads. Another way of speeding up the process is to remove the <code>--deltas</code> flag to prevent it from generating deltas. It may also be prudent to set nice &amp; ionice levels depending on your system. For non-ssd storage, and/or SAN storage, I typically recommend limiting workers to no more than half of the available threads, nice level of 15, and ionice class of 3. This will make sure the system has plenty of resources to handle large repos without impacting other services. For SSD backed storage, especially local SSDs, ionice typically is not needed unless your storage throughput is limited by something like LUKS.</p>","tags":["rocky","rhel","ubuntu","debian","arch"]},{"location":"how-to/MDRAID/","title":"MD Raid Devices","text":"<p>Get Status</p> <pre><code>cat /proc/mdstat # This should give you the status on every box\nmdadm -Esv # Get the overall status and other information about the array\n</code></pre> <p>[!success]</p> <p><pre><code>root@hostname:~# mdadm -Esv\nARRAY /dev/md/127  level=raid0 metadata=1.2 num-devices=2 UUID=f08bed23:a5b4764a:4a7151ad:65cddd4e name=hostymchostface:127\n   devices=/dev/sdc1,/dev/sdb1\n</code></pre> </p>","tags":["mdraid","storage","raid","linux"]},{"location":"how-to/MDRAID/#troubleshooting","title":"Troubleshooting","text":"<p>Example</p> <pre><code>sudo mdadm -Esv\nsudo mdadm  --stop /dev/md*\nsudo mdadm --misc --scan --detail /dev/md0\nsudo mdadm -v --assemble \"$array\" \"$disk1$part\" \"$disk2$part\"\n</code></pre> <p>If you're getting <code>mdadm: cannot open /dev/sdb1: Device or resource busy</code> or something like that chances are is that the array isn't created correctly. You will need to stop the array with <code>mdadm --stop /dev/md*</code> and recreate it.</p> <p>The rest of the troubleshooting commands are for scanning and re-assembling arrays for example you put the disks in the wrong order. It happens to everyone at least once :)</p>","tags":["mdraid","storage","raid","linux"]},{"location":"how-to/MDRAID/#creating-an-array","title":"Creating an Array","text":"<p>You can make an array a lot of different ways, the current best way is with LVM &amp; DMRAID; however there are A LOT of cases where MDRaid is better to use. A good example is with compatibly with hardware controllers. Dell's PERC orders and creates it's discs in a way that is compatible with importing and exporting via Linux MD devices.</p> <p>Example</p> <pre><code>mdadm --create /dev/md127 --level=stripe --raid-devices=2 --chunk=16 /dev/sdb1 /dev/sdc1\n</code></pre> <p>This example creates a MD device <code>/dev/md127</code> the level is stripe meaning it is striping the data aka RAID0. The <code>raid-devices</code> and <code>chunk</code> are the chunk aka strip size and the number of disks in the array. In this case <code>/dev/sdb1 /dev/sdc1</code> are the two disks in the example. You can configure this as needed</p> <p>Seealso</p> <pre><code>man mdadm\n</code></pre>","tags":["mdraid","storage","raid","linux"]},{"location":"how-to/MDRAID/#rebuilding-an-array","title":"Rebuilding an Array","text":"<p>[[Technical Notes]]</p>","tags":["mdraid","storage","raid","linux"]},{"location":"how-to/MySQL/","title":"How to MYSQL","text":"","tags":["mysql","mariadb"]},{"location":"how-to/MySQL/#dump-database-to-a-file","title":"Dump Database to a File","text":"<p>To backup, transfer, etc a database you will need to create a dump. You can dump all the databases or just a single data base. The difference is specifying a database name or the --all-databases flag.</p> <p>Dump a single database  </p> <p><code>mysqldump -u USER -p DatabaseNameHere &gt; DatabaseNameHere-YYYY-MM-DD.sql</code></p> <p>Dump all databases with compression!  </p> <p><code>mysqldump -u USER -p --all-databases | zstd &gt;all-databases-YYYY-MM-DD.sql.zst</code></p> <p>You can also do the same over SSH. You can dump all or just a single database just like above. This is really handy for when you need to transfer a database to another server</p> <p>Dump Over SSH  </p> <p><code>mysqldump -u USER -p DATABASE | ssh USER@HOSTNAME mysql -u USER</code></p>","tags":["mysql","mariadb"]},{"location":"how-to/MySQL/#restoring-a-database","title":"Restoring a Database","text":"<p>You should do the above to dump the database first, just in case. Unless you're REALLY sure of your backups\u2026</p> <p>To restore a database you're going to the same process in reverse. So let's take a compressed dump and put it back into mysql</p> <p>Restoring compressed dump  </p> <p><code>mysql -u USER -p DatabaseNameHere &lt; zstd DatabaseNameHere-YYYY-MM-DD.sql.zst</code></p> <p>Doing the same thing but over ssh  </p> <p><code>zstd DatabaseNameHere-YYYY-MM-DD.sql.zst | ssh USER@HOSTNAME \"mysql -u USER -p DatabaseNameHere\"</code></p> <p>You can mix &amp; match as needed. Just make sure you're backups are good otherwise someone's gonna get hurt real bad\u2026</p>","tags":["mysql","mariadb"]},{"location":"how-to/MySQL/#creating-databases","title":"Creating Databases","text":"<p>Let's say you need to create a database and user to connect to the database, you also need that user to be able to connect from the localhost and other systems.</p> <p>First things first, create a password hash for the user. You can generate it a number of ways, the easiest for this example would be using mysql it self. You can also use python if needed/wanted. Another good resource for generating stuff is RFC Tools</p> <p>With MySQL</p> <pre><code>mysql -NBe \"select password('PasswordHere')\"\n</code></pre> <p>With Python</p> <pre><code>python -c 'from hashlib import sha1; print \"*\" + sha1(sha1(\"PasswordHere\").digest()).hexdigest().upper()'\n</code></pre> <p>Once you have the password hash for the user you want to create, use the following example to create your database</p> <p>Example</p> <pre><code>CREATE DATABASE DatabaseNameHere;\nGRANT ALL PRIVILEGES ON DatabaseNameHere.* to 'UserNameHere'@'%' IDENTIFIED BY PASSWORD '*920018161824B14A1067A69626595E68CB8284CB';\nGRANT ALL PRIVILEGES ON DatabaseNameHere.* to 'UserNameHere'@'localhost' IDENTIFIED BY\nPASSWORD '*920018161824B14A1067A69626595E68CB8284CB';\n</code></pre> <p>[[Technical Notes]]</p>","tags":["mysql","mariadb"]},{"location":"how-to/Python/","title":"Python Cert Errors","text":"<p>MacOS</p> <pre><code>cd /Applications/Python\\ 3.11/\n./Install\\ Certificates.command\n</code></pre> <p>AND/OR</p> <pre><code>pip install -U certifi\n</code></pre> <p>https://stackoverflow.com/questions/40684543/how-to-make-python-use-ca-certificates-from-mac-os-truststore</p>","tags":["python"]},{"location":"how-to/SSH/","title":"SSH","text":"","tags":["ssh","putty","winget","git"]},{"location":"how-to/SSH/#creating-a-ssh-key","title":"Creating a Ssh Key","text":"","tags":["ssh","putty","winget","git"]},{"location":"how-to/SSH/#linux-macos","title":"Linux / MacOS","text":"<p>Example</p> <pre><code>ssh-keygen -t ed25519 -C \"userid and/or email here\"\n</code></pre> <p>Once your key is created you should find it located in <code>~/.ssh</code> using the default options it the path would be <code>~/.ssh/id_ed25519</code> for the private key and <code>~/.ssh/id_ed25519.pub</code> for the public key.</p>","tags":["ssh","putty","winget","git"]},{"location":"how-to/SSH/#putty","title":"Putty","text":"<p>Attention:  </p> <p>Make sure you have putty installed for this to work. If you do not have it installed use the package manager of your choice</p> <p>Using winget to install Putty  </p> <p><code>winget install -e --id PuTTY.PuTTY</code></p> <p> </p> <p>You can do this with the gui version; I do not have have the gui version, so you'll have to translate this if you want to go down that road</p> <p>Creating a new putty key  </p> <p><code>puttygen -t ed25519 -C \"userid and/or email here\" -o putty_key.ppk</code></p>","tags":["ssh","putty","winget","git"]},{"location":"how-to/SSH/#extracting-keys","title":"Extracting Keys","text":"<p>To use your putty key on without putty you will need to extract the keys. Keep track of where you extra the key too and the file names created, you will need this information later. Also treat these keys like you would a password, they're sensitive information that needs to be protected.</p>","tags":["ssh","putty","winget","git"]},{"location":"how-to/SSH/#public-key","title":"Public Key","text":"<p>To get your public key from your putty key you will need to extract it</p> <p>Extracting Public Key  </p> <p><code>puttygen putty_key.ppk -O public-openssh -o putty_key.pub</code></p>","tags":["ssh","putty","winget","git"]},{"location":"how-to/SSH/#private-key","title":"Private Key","text":"<p>To get your private key from your putty key you will need to extract it</p> <p>Extracting Private Key  </p> <p><code>puttygen putty_key.ppk -O private-openssh -o putty_key</code></p>","tags":["ssh","putty","winget","git"]},{"location":"how-to/SSH/#convert-openssh-key-to-putty-key","title":"Convert Openssh Key to Putty Key","text":"<p>To convert an openssh key to putty key you will need the private key file as well as any passwords that may or may not be securing that key. This will most likely not apply to anyone unless they want to take an existing key and use in putty</p> <p>Converting the key  </p> <p><code>puttygen id_ed25519 -o putty_key.ppk</code></p>","tags":["ssh","putty","winget","git"]},{"location":"how-to/SSH/#using-your-ssh-key","title":"Using Your SSH Key","text":"<p>To use your key, simply ssh to a server. It should instantly allow you in without prompting. Putty users will have to enter their user name depending on how they have their connection configured.</p> <p> </p> <p>If you're having problems you may need to add the keys to your ssh-agent. <code>ssh-agent -a ~/.ssh/id_ed25519</code> Putty should do this for you, you may have to go into the connection settings and tell it to use the key. I believe moba works the same way.</p>","tags":["ssh","putty","winget","git"]},{"location":"how-to/SSH/#agent-forwarding","title":"Agent Forwarding","text":"<p>For MacOS you will need to do <code>ssh-add --apple-use-keychain</code> to add your keys to the keychain for Agent Forwarding to work correctly</p> <p>When you use agent forwarding it will allow your keys to be used on a remote system that you're connected too. You do this with the <code>-A</code> flag so <code>ssh -A user@host</code> however you can configure your ssh config to do this for you automatically. Make sure you place this at the END of your config</p> <p> </p> <p><code>~/.ssh/config</code></p> <pre><code>host *\n Compression yes\n StrictHostKeyChecking no\n ForwardAgent yes\n</code></pre> <p><code>host *</code> says use these options on anything that matches. This is why we put it at the bottom of <code>~/.ssh/confg</code> because it works on a first match priceable. <code>compression yes</code> means that it will use compression, this is helpful for low-bandwidth connections and data transfers. <code>StrictHostKeyChecking no</code> says don't alert me to accept keys. Not a great idea for most things, but not something we can avoid with our current setup. <code>ForwardAgent yes</code> means that it will forward the ssh-agent to the destination connection. This is the main thing we want, the other options are helpful but not required.</p>","tags":["ssh","putty","winget","git"]},{"location":"how-to/SSH/#ssh-agent-forwarding-via-sudo","title":"SSH Agent Forwarding via Sudo","text":"<p>Now that you're forwarding your agent and you're able to ssh into other systems from the system you're connected to, let's assume you need to become root or another user. To do this you will need to forward your shell and environment. Do do this you will do <code>sudo -E -s</code> or <code>sudo -E -s -u username</code>. this will allow you to forward your agent from your system, to a remote system, over sudo, and use your keys that way. The <code>-E</code> flag forwards your environment and the <code>-s</code> forwards your shell.</p> <p>This example forwards your agent, connects to a host, then drops you into root with your agent forwarded</p> <p>Example</p> <pre><code>ssh -A user@hostname\nsudo -E -s\n</code></pre>","tags":["ssh","putty","winget","git"]},{"location":"how-to/SSH/#ssh-host-jumping","title":"SSH Host Jumping","text":"<p>To use another host as a jumpbox you have to use the <code>-J</code> flag. You can combine this with the <code>-A</code> to forward your agent too.</p> <p>Example</p> <pre><code># Use a system to connect to another system\nssh -J user@jump-box user@destination-server\n# Jump from jumpbox to jumpbox2 to jumpbox3 to destination\nssh -J user@jumpbox,user@jumpbox2,user@jumpbox3 user@destination\n</code></pre> <p>If you're forwarding your agent and your public key is on the various servers you can jump to all of them adding the <code>-A</code> flag.</p>","tags":["ssh","putty","winget","git"]},{"location":"how-to/SSH/#ssh-key-signing","title":"SSH Key Signing","text":"","tags":["ssh","putty","winget","git"]},{"location":"how-to/SSH/#configure-git-to-use-your-ssh-key","title":"Configure Git to Use Your Ssh Key","text":"<p>Now configure git so it knows about your signing key</p> <pre><code>git config --global gpg.format ssh\ngit config --global user.signingkey \"${HOME}/.ssh/id_ed25519.pub\"\n</code></pre> <p>Now when you commit on git add a -S to sign it!</p> <pre><code>git commit -Sam \"Adding, Signing, and Commenting!\"\n</code></pre> <p>If you want to skip adding the S then set:</p> <pre><code>git config --global commit.gpgsign true\n</code></pre>","tags":["ssh","putty","winget","git"]},{"location":"how-to/SSH/#other-uses-beside-git","title":"Other Uses beside Git","text":"","tags":["ssh","putty","winget","git"]},{"location":"how-to/SSH/#signing-data","title":"Signing Data","text":"<p>Now let's take a step further! How about signing files, data, etc? You can do that with your ssh key! Why would you want to do this? You can ensure data integrity and prove that the data came from you.</p> <pre><code>ssh-keygen -Y sign -f ~/.ssh/id_ed25519 -n file FILENAMEHERE\n</code></pre> <p>So lets break this down <code>-Y sign</code> is telling it that you're going to sign something, then comes the path to your private key, next is the name space, since we're signing a file we tell it <code>-n file</code>.</p>","tags":["ssh","putty","winget","git"]},{"location":"how-to/SSH/#verifying-data","title":"Verifying Data","text":"<p>Okay, so we signed a file, but how do we verify it?</p> <pre><code>ssh-keygen -Y verify -f allowed_signers -I hugh.smalley@lexisnexisrisk.com -n file -s FILENAMEHERE.sig &lt;FILENAMEHERE\n</code></pre> <p>Just like signing <code>-Y verify</code> is telling it that we want to verify something. <code>-f allow_signers</code> is telling it the name of the file with the information to lookup public keys. Much like the authorized_keys file lets ssh know they's keys are allowed to connect.</p> <p>For example here's my keys in the allowed_signers file.</p> <pre><code>hugh.smalley@lexisnexisrisk.com sk-ssh-ed25519@openssh.com AAAAGnNrLXNzaC1lZDI1NTE5QG9wZW5zc2guY29tAAAAIPEroRTKtLMu9EXxFXXNm8bzA1w/c4v7gFKeFPXmHII1AAAABHNzaDo= Yubikey 5\nhugh.smalley@lexisnexisrisk.com ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIFuAYj8uDz7o5qJzHrEohvfpX/RWBoqudHRoaD+6dR+X Macbook Pro\n</code></pre> <p>The first section is a comma delineated list of identifiers eg email addresses. The next section is the type of key, eg ssh-ed25519, ssh-rsa, etc. Lastly the public key.</p> <p>To continue the <code>-I</code> says the name of the identity to check in the allowed_signers file.<code>-n file</code> is again the name space, <code>-s</code>is the signature file and <code>&lt;FILENAMEHERE</code>is the file we're checking.</p>","tags":["ssh","putty","winget","git"]},{"location":"how-to/SSH/#handy-shortcuts","title":"Handy Shortcuts","text":"<p>You can wrap this up in some functions to throw into your .bashrc,.zshrc,etc..</p> <pre><code>ssh_sign () {\nssh-keygen -Y sign -f ~/.ssh/id_ed25519 -n file \"${1}\"\n}\nssh_verify () {\nssh-keygen -Y verify -f allowed_signers -I \"${1}\" -n file -s \"${2}.sig\" &lt;\"${2}\"\n}\n</code></pre> <p>Now you can sign commits and other data with ssh!</p> <p> you did it!</p>","tags":["ssh","putty","winget","git"]},{"location":"how-to/SSH/#see-also","title":"See Also","text":"<p>Github has a guide for creating, using, and adding ssh keys. I suggest you read that if you want to know more or add your keys to github.</p>","tags":["ssh","putty","winget","git"]},{"location":"how-to/SVN/","title":"SVN","text":"<p>Info</p> <p>Make sure your EDITORs are setup, if in doubt</p> <pre><code>export EDITOR=vim; export SVN_EDITOR=vim\n</code></pre>","tags":["svn"]},{"location":"how-to/SVN/#common-svn-commands","title":"Common SVN Commands","text":"","tags":["svn"]},{"location":"how-to/SVN/#checking-out-a-repo","title":"Checking out a Repo","text":"<p>Example</p> <pre><code>svn co https://genesis.hpcc.risk.regn.net/repos/scripts\n</code></pre> <p>This will checkout the scripts directory the repos.</p>","tags":["svn"]},{"location":"how-to/SVN/#checking-the-status","title":"Checking the Status","text":"<p>Example</p> <pre><code>svn info\nsvn status\nsvn log\nsvn log --diff\n</code></pre> <p>With the above commands it will assume your current working directory as the path. You can use a file path such as <code>~/svn/scripts</code> you can also a URI like <code>file:///home/user/svn/scripts/file_or_dir_here</code> or <code>https://genesis.risk.regn.net/repos/scripts/file_or_dir_here</code></p> <p>When using <code>svn log</code> commands you should pipe it into <code>less</code> or <code>head</code> otherwise there will be a lot of information in your terminal</p>","tags":["svn"]},{"location":"how-to/SVN/#committing-changes","title":"Committing Changes","text":"<p>Example</p> <pre><code>svn commit -m \"Commit Message Here\"\n</code></pre>","tags":["svn"]},{"location":"how-to/SVN/#adding-a-new-file","title":"Adding a New File","text":"<p>Example</p> <pre><code>svn add NewFileHere\n</code></pre>","tags":["svn"]},{"location":"how-to/SVN/#creating-a-new-directory","title":"Creating a New Directory","text":"<p>Example</p> <pre><code>svn mkdir NewDirHere\n</code></pre>","tags":["svn"]},{"location":"how-to/SVN/#removing-a-data","title":"Removing a Data","text":"<p>Example</p> <pre><code>svn rm DataToRemoveHere\n</code></pre>","tags":["svn"]},{"location":"how-to/SVN/#reverting-changes","title":"Reverting Changes","text":"<p>Example</p> <pre><code>svn merge -r current_version:previous_version\n</code></pre> <p>There is a shortcut to just revert the latest change <code>svn merge -c -REV .</code> or if you need to do multiple commits add them with a comma <code>svn merge -c -REV,-REV .</code></p> <p>Once you do that, you will then need to commit the changes. <code>svn commit -m \"Reverted to REV\"</code></p> <p>Metadata [[Technical Notes]]</p>","tags":["svn"]},{"location":"how-to/TAR/","title":"How I Learned to Love <code>tar</code>","text":"<p>Tar stands for tape archive. So if you think of tar files like tape archives it makes it a lot easier to manage. Or so I think because I worked with tapes for years.</p>","tags":["tar"]},{"location":"how-to/TAR/#create-an-archive","title":"Create an Archive","text":"<p>Creating an archive is as simple as <code>-cf</code> the c is create and f is for file then your data paths</p> <p>Example</p> <pre><code>tar -cf file.name.tar Dir.To.Tar or.Files.too\n</code></pre>","tags":["tar"]},{"location":"how-to/TAR/#compression-decompression","title":"Compression &amp; Decompression","text":"<p>Tar has an automatic mode for a while now, as long as you a way to do it, tar will figure it out most of the time for you. Let's compress something with the new hotness of zstd. In this example <code>-avcf</code> stands for automatic, verbose, create, file</p> <p>Example</p> <pre><code>tar -avcf file.name.tar.zst Dir.To.Tar and.or.Files.too\n</code></pre> <p>Now how about extracting a file?</p> <p>Example</p> <pre><code>tar -avxf file.name.tar.gz\n# or to somewhere else\ntar -avxf file.name.tar.gz -C /your/path/here\n</code></pre> <p>In that example we told tar to use the flags <code>-avxf</code> that stands for automatic, verbose, extract, file.</p>","tags":["tar"]},{"location":"how-to/TAR/#using-custom-compression","title":"Using Custom Compression","text":"<p>If you need to use something that isn't built into tar, for instance if you're using a version of tar that does not support zstd you can use <code>-I</code> to set the program to use for compression</p> <p>Example</p> <pre><code>tar -I zstd -cf filename.tar.zst /your/path/here\n</code></pre> <p>Note</p> <ul> <li> <p>Keep in mind, although this doesn\u2019t apply to tar itself, when dealing with most compression programs there is a big difference between <code>-e</code> and <code>-x</code> being that <code>-e</code> will preserve paths.</p> <p>So if Alice made a tar file in <code>/home/alice/mytardis</code> that means that when Bob uses <code>-e</code> it will try to extract the data to the same path. So if Bob wants <code>/home/bob/mytardis</code> rather than <code>/home/alice/tardis</code> Bob needs to use the <code>-x</code> flag.</p> </li> </ul>","tags":["tar"]},{"location":"how-to/TAR/#adding-and-removing-data","title":"Adding and Removing Data","text":"<p>So you want to add or remove data from your tar file? Good news, you can! </p> <p>However it's not as easy as you may like it to be. In most causes it might be a lot easier to use the <code>--exclude</code> flag and remake the file. However let's solve this problem one step at a time.</p> <p> </p> <p>Did you know the <code>--exlude</code> flag also works for extracting?</p> <p>First things first, let's get a list of all the file in the tar. Here are two examples on how to list things and search things in a tar file.</p> <p>Example</p> <pre><code>tar -atf file.name.here.tar.bz2\ntar -atf file.name.here.tar.zst --wildcards '*.png'\n</code></pre> <p>Tip</p> <ul> <li> <p>Don't worry if you leave off the <code>-a</code> as tar is pretty smart and will figure out that it's compressed. Just remember to use the main part of the command e.g. <code>-tf</code> at min.</p> </li> </ul> <p>Now that you know the path in the file to the data you're going to use the <code>--delete</code> flag to remove the data or the <code>--append</code> flag to append data.</p> <p> </p> <p>Keep in mind, there is no way to append or delete from a compressed archive.</p> <p>If you have a compressed tar you will need to decompress it, let's use <code>file.name.here.tar.zstd</code> as an example. This works the same for anything the file was compressed with e.g. <code>zstd</code> or <code>gzip</code>.</p> <p>Example</p> <pre><code>zstd -d file.name.here.tar.zstd\ntar -vf file.name.here.tar --delete path/here/oops.foo\ntar -vf file.name.here.tar --append path/here/yes_this.bar\nzstd file.name.here.tar -o file.name.here.tar.zstd\n</code></pre> <p>So what we did is decompress <code>file.name.here.tar.zstd</code> and that became <code>file.name.here.tar</code>. Now we removed <code>oops.foo</code> and added <code>yes_this.bar</code> to the tar file. Lastly we compressed <code>file.name.here.tar</code> to create a shiny new <code>file.name.here.tar.zstd</code>.</p>","tags":["tar"]},{"location":"how-to/TAR/#backups-with-tar","title":"Backups with Tar","text":"<p>Tar is or was a backup tool first and for most, so it goes without saying you can do the normal differential and incremental backups with it. Differential backups are hard to automate so let's just stick with incremental backups for now.</p>","tags":["tar"]},{"location":"how-to/TAR/#give-it-the-g","title":"Give it the <code>-g</code>","text":"<p>When you want to create an incremental backup you will need to first create a full backup and a snapshot file.</p> <p>Example</p> <pre><code>tar -I zstd -g /path/to/backup/backup.snar -cf /path/to/backup/full_backup.tar.zst /path/to/data/here\n</code></pre> <p>This command will compress the backup using zstd, create the snar file, and make a fill backup. Once that's done you can make as many backups you want and the snar will store lists of changes between backups.</p> <p>Now to make our first incremental backup!</p> <p>Example</p> <pre><code>tar -I zstd -g /path/to/backup/backup.snar -cf /path/to/backup/$(date '+%F').tar.zst /path/to/data/here\n</code></pre>","tags":["tar"]},{"location":"how-to/TAR/#excluding-data","title":"Excluding Data","text":"<p>Tar can exclude data a number of ways</p>","tags":["tar"]},{"location":"how-to/TAR/#file-steaming-with-tar","title":"File Steaming with Tar","text":"<p>Tar was created to stream data to tapes. You can do a lot of things that you wouldn't think you should be able to do with it. However thanks to the Unix way\u2026 EVERYTHING is a file.</p>","tags":["tar"]},{"location":"how-to/TAR/#copying-a-large-amount-of-small-files","title":"Copying a Large Amount of Small Files","text":"<p>Let's say we have 10 million small files that we need to move from <code>/var/omg/why/did/you/do/this</code> to <code>/mnt/this/is/where/it/should/have/been</code> that is going to take a while right? Well\u2026.</p> <p>Example</p> <pre><code>tar -cf - /var/omg/why/did/you/do/this | tar -xf - -C /mnt/this/is/where/it/should/have/been\n</code></pre> <p>You can also do this over ssh! Now let's add some compression too!</p> <p>Example</p> <pre><code># Make a file on the other end\ntar -cf - /var/lib/data | zstd | ssh user@hostname \"cat &gt;/var/backups/backup.tar.zst\"\n# Send the data compressed with a progress bar!\ntar -cf - /var/lib/data | pv | zstd | ssh user@hostname tar -axf - -C /var/lib/data/\n# Send the data with a progress bar\ntar -cf - /var/lib/data | pv | ssh user@hostname tar -xf - -C /var/lib/data/\n# Get the data\nssh user@hostname \"tar -cf - /var/lib/data\" | tar -xvf - -C /var/lib/data/\n</code></pre> <p>Note</p> <ul> <li> <p>The pipe view command <code>pv</code> will give you different information depending on where it's put and what flags are used. The example above shows the raw data being passed. If you wanted to see the compressed data passed then you should put it after <code>zstd</code></p> </li> </ul> <p>The above examples show how to use tar with ssh. You can mix and match as needed. Your only limit is your creativity!</p> <p>Oh and that being said, <code>rsync</code> is almost always the better tool for sending data around. The edge cases being special files like symbolic links, special devices, sockets, named pipes, etc. If you're sending and backing up anything like that or other data rsync is bad for, tar is your go too.</p> <p>[[Technical Notes]]</p>","tags":["tar"]},{"location":"how-to/VIM/","title":"VIM (and VI)","text":"<p>Quit VI and VIM  </p> <p><code>:q</code> - Quit <code>:q!</code> - Force Quit, DO NOT SAVE <code>:wq</code> - Write (Save) Changes &amp; Quit <code>:wq!</code> - Write Changes &amp; Force Quit</p> <p>Paste Mode aka stop trying to be helpful and format things for me  </p> <p><code>:set paste</code></p> <p>Search and Replace  </p> <p><code>:%s/STRING_OR_REGEX/REPLACE_WITH/g</code> &gt; <code>:%s/BADSTRING/GOODSTRING/g</code> &gt; <code>:%s/192\\.168\\.100\\.100/10.100.100.100/g</code></p> <p>Remove Trailing Whitespaces  </p> <p><code>:%s/\\s\\+$//</code></p> <p>Macro Mode  </p> <p><code>qq</code></p>","tags":["vim","vi"]},{"location":"how-to/VIM/#vim","title":"Vim","text":"","tags":["vim","vi"]},{"location":"how-to/Windows/","title":"Windows","text":"","tags":["windows","powershell","winget","chocolatey"]},{"location":"how-to/Windows/#setup-script","title":"Setup Script","text":"<p>Here's a really good looking setup script that's actively maintained</p> <pre><code>PowerShell -NoProfile -ExecutionPolicy Bypass -Command \"iex ((New-Object System.Net.WebClient).DownloadString('https://gist.githubusercontent.com/mikepruett3/7ca6518051383ee14f9cf8ae63ba18a7/raw/shell-setup.ps1'))\"\n</code></pre> <p>[[shell-setup.ps1]]</p> <p>[[Technical Notes]]</p>","tags":["windows","powershell","winget","chocolatey"]},{"location":"recipes/Marry%20Me%20Chicken/","title":"Marry Me Chicken","text":"","tags":["chicken recipes","chicken"]},{"location":"recipes/Marry%20Me%20Chicken/#ingredients","title":"Ingredients","text":"<p>3 - Chicken Breasts, slic 100g - flour 10 - cherry tomatoes, sliced in half 150g - sun dried tomatoes 2tbsp - olive oil (or oil from sun dried tomatoes) 4 - finely diced garlic cloves 200ml - stock (chicken or veg) 300ml - heavy cream (or thick coconut milk) 30g - grated parm +10g for garnish 1 tsp - chili flakes (optional) 1 tsp - tomato paste 1tbsp - oregano fresh basil for garnish s&amp;p to taste</p>","tags":["chicken recipes","chicken"]},{"location":"recipes/Marry%20Me%20Chicken/#prepare","title":"Prepare","text":"<ol> <li>Preheat oven to 140c and place sliced cherry tomatoes on and drizel with oil and s&amp;p for 45min</li> <li>Season chicken with s&amp;p and coat with flour</li> <li>Preheat frying pan with olive oil and butter and brown chicken, set aside when done</li> <li>Saute garlic, add stock, next add cream &amp; cheese. Simmer for a few min and add tomato paste and spices.</li> <li>Add chopped sun dried tomotoes and chicken back into the pot and simmer until cooked</li> <li>Garnish with cherry tomotoes, basil, parsley and extra parm. Serve over pasta/rice/pearl barley.</li> <li>Enjoy</li> </ol>","tags":["chicken recipes","chicken"]},{"location":"tags/","title":"Tags","text":"<p>Following is a list of relevant tags:</p>"},{"location":"tags/#ansible","title":"ansible","text":"<ul> <li>Ansible - How to write a playbook</li> <li>Ansible - Getting Started</li> </ul>"},{"location":"tags/#arch","title":"arch","text":"<ul> <li>Linux</li> </ul>"},{"location":"tags/#audio","title":"audio","text":"<ul> <li>FFMPEG and YOU!</li> </ul>"},{"location":"tags/#chicken","title":"chicken","text":"<ul> <li>Marry Me Chicken</li> </ul>"},{"location":"tags/#chicken-recipes","title":"chicken recipes","text":"<ul> <li>Marry Me Chicken</li> </ul>"},{"location":"tags/#chocolatey","title":"chocolatey","text":"<ul> <li>Windows</li> </ul>"},{"location":"tags/#debian","title":"debian","text":"<ul> <li>Linux</li> </ul>"},{"location":"tags/#docker","title":"docker","text":"<ul> <li>Docker</li> </ul>"},{"location":"tags/#ffmpeg","title":"ffmpeg","text":"<ul> <li>FFMPEG and YOU!</li> </ul>"},{"location":"tags/#frontmatter","title":"frontmatter","text":"<ul> <li>Markdown Metadata, its meta-tastic!</li> </ul>"},{"location":"tags/#git","title":"git","text":"<ul> <li>GIT</li> <li>SSH</li> </ul>"},{"location":"tags/#ipfs","title":"ipfs","text":"<ul> <li>This is My Second IPFS Post</li> <li>This is My First IPFS Post</li> </ul>"},{"location":"tags/#json","title":"json","text":"<ul> <li>JSON</li> </ul>"},{"location":"tags/#linux","title":"linux","text":"<ul> <li>MDRAID</li> </ul>"},{"location":"tags/#macos","title":"macos","text":"<ul> <li>Docker</li> </ul>"},{"location":"tags/#makemkv","title":"makemkv","text":"<ul> <li>FFMPEG and YOU!</li> </ul>"},{"location":"tags/#mariadb","title":"mariadb","text":"<ul> <li>MYSQL</li> </ul>"},{"location":"tags/#markdown","title":"markdown","text":"<ul> <li>Markdown Metadata, its meta-tastic!</li> </ul>"},{"location":"tags/#mdraid","title":"mdraid","text":"<ul> <li>MDRAID</li> </ul>"},{"location":"tags/#metadata","title":"metadata","text":"<ul> <li>Markdown Metadata, its meta-tastic!</li> </ul>"},{"location":"tags/#mysql","title":"mysql","text":"<ul> <li>MYSQL</li> </ul>"},{"location":"tags/#podman","title":"podman","text":"<ul> <li>Docker</li> </ul>"},{"location":"tags/#powershell","title":"powershell","text":"<ul> <li>Windows</li> </ul>"},{"location":"tags/#putty","title":"putty","text":"<ul> <li>SSH</li> </ul>"},{"location":"tags/#python","title":"python","text":"<ul> <li>Python</li> </ul>"},{"location":"tags/#raid","title":"raid","text":"<ul> <li>MDRAID</li> </ul>"},{"location":"tags/#rhel","title":"rhel","text":"<ul> <li>Linux</li> </ul>"},{"location":"tags/#rocky","title":"rocky","text":"<ul> <li>Linux</li> </ul>"},{"location":"tags/#ssh","title":"ssh","text":"<ul> <li>Ansible - Getting Started</li> <li>SSH</li> </ul>"},{"location":"tags/#storage","title":"storage","text":"<ul> <li>MDRAID</li> </ul>"},{"location":"tags/#svn","title":"svn","text":"<ul> <li>SVN</li> </ul>"},{"location":"tags/#tar","title":"tar","text":"<ul> <li>TAR</li> </ul>"},{"location":"tags/#ubuntu","title":"ubuntu","text":"<ul> <li>Linux</li> </ul>"},{"location":"tags/#vi","title":"vi","text":"<ul> <li>VIM</li> </ul>"},{"location":"tags/#video","title":"video","text":"<ul> <li>FFMPEG and YOU!</li> </ul>"},{"location":"tags/#vim","title":"vim","text":"<ul> <li>VIM</li> </ul>"},{"location":"tags/#windows","title":"windows","text":"<ul> <li>Windows</li> </ul>"},{"location":"tags/#winget","title":"winget","text":"<ul> <li>SSH</li> <li>Windows</li> </ul>"}]}